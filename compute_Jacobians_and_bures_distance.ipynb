{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12859f88-fdd1-4df7-9d03-74d64a0ce35e",
   "metadata": {},
   "source": [
    "### Compute and save Jacobians and Bures distances for analysis\n",
    "\n",
    "Example code extracting representations, computing Jacobians and Bures distances, and saving/loading all these things once computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699ef08b-aa14-4461-8952-b3173f9830d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import dsutils \n",
    "import metrics\n",
    "import jsutils\n",
    "import extract_internal_reps\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842b5cf2-34d5-429c-a452-d282de15a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'maxvit_t',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available models (from torch hub)\n",
    "\n",
    "avail_models = models.list_models(module=torchvision.models)\n",
    "avail_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bdc7b-b8fe-41e7-b8c6-0816c11c0e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_base done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_large done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_small done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_tiny done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet121 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet161 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet169 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet201 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b0 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b1 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b2 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b4 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b5 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b6 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b7 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_v2_l done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_v2_m done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_v2_s done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googlenet done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_v3 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxvit_t done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet0_5 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet0_75 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet1_0 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet1_3 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_large done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v3_small done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regnet_x_16gf done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regnet_x_1_6gf done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regnet_x_32gf done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "# Extract representations resulting from probe inputs in data_dir\n",
    "\n",
    "data_dir = '../imagenet-sample-images'\n",
    "\n",
    "# internal_reps = []\n",
    "# model_2nds = []\n",
    "repDict = {}\n",
    "\n",
    "for model in avail_models:\n",
    "    repDict.clear()\n",
    "    x1, model_2nd = extract_internal_reps.extract_rep_gen(model, data_dir, weights=\"first\")\n",
    "    repDict[model] = [x1,model_2nd]\n",
    "    # model_2nds.append(model_2nd)\n",
    "    # internal_reps.append(x1)\n",
    "    with open(model + '_internal_rep_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(repDict, f)\n",
    "    print(model + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131f72b-b802-4e2f-8c0f-7b410d64a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract representations resulting from probe inputs in data_dir\n",
    "\n",
    "# OLD METHOD\n",
    "\n",
    "# data_dir = '../imagenet-sample-images'\n",
    "\n",
    "# internal_reps = []\n",
    "# model_2nds = []\n",
    "# repDict = {}\n",
    "\n",
    "# for model in model_names:\n",
    "#     x1, model_2nd = extract_internal_reps.extract_rep(model, data_dir)\n",
    "#     repDict[model] = [x1,model_2nd]\n",
    "#     model_2nds.append(model_2nd)\n",
    "#     internal_reps.append(x1)\n",
    "#     print(model + \" done\")\n",
    "\n",
    "# Save extracted representations\n",
    "\n",
    "# with open('internal_reps_with_model_2nd_half_full_classifier.pkl', 'wb') as f:\n",
    "#     pickle.dump(repDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a60eb3-e0b7-4024-82ef-9b5e53be914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted representations\n",
    "\n",
    "# Load a specified set of internal reps in a dictionary \n",
    "\n",
    "repDict = {}\n",
    "\n",
    "# Models you want to load \n",
    "model_names = [\"alexnet\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\", \"vgg16\"]\n",
    "\n",
    "N_models = len(model_names)\n",
    "for model_name in model_names:\n",
    "    with open(model_name + '_internal_rep_classifier.pkl', 'rb') as f:\n",
    "        new_reps = pickle.load(f)\n",
    "        repDict.update(new_reps)\n",
    "        print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d780bb-82f7-43c8-a108-15301945c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute decoding Jacobians and save\n",
    "\n",
    "# Takes a while\n",
    "\n",
    "import pickle\n",
    "J_dict_rbyn = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    J_dict_rbyn.clear()\n",
    "    Js = jsutils.decoding_jacobian(repDict[model_name][0], repDict[model_name][1])\n",
    "    J_dict_rbyn[model_name] = Js\n",
    "    with open(model_name + '_decoding_Js_rbyn.pkl', 'wb') as f:\n",
    "        pickle.dump(J_dict_rbyn, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d40dcd-55db-48fd-9e67-3bad746889a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Jacobian lists from a list of M, r by N Jacobians to a list of r, M by N Jacobians (if desired)\n",
    "\n",
    "J_dict_mbyn = {}\n",
    "for model_name in model_names:\n",
    "    J_dict_mbyn.clear()\n",
    "    Js_mbyn = jsutils.convert_Jacobian(J_dict_rbyn, model_name)\n",
    "    J_dict_mbyn[model_name] = Js_mbyn\n",
    "    with open(model_name + '_decoding_Js_mbyn.pkl', 'wb') as f:\n",
    "        pickle.dump(J_dict_mbyn, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6a9dd-0a66-45bb-ab5a-a737737bd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Jacobians\n",
    "\n",
    "J_dict = jsutils.flatten_Jacobian(J_dict_rbyn)\n",
    "\n",
    "for model_name in model_names:\n",
    "    Js = {model_name: J_dict[model_name]}\n",
    "    with open(model_name + '_decoding_Js_stacked.pkl', 'wb') as f:\n",
    "        pickle.dump(Js, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4ce74-8632-4a60-823d-351a2225b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jacobians\n",
    "# loads a subset of models' Jacobians\n",
    "\n",
    "J_dict = {}\n",
    "\n",
    "model_names = [\"alexnet\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\",\"vgg16\"]\n",
    "\n",
    "N_models = len(model_names)\n",
    "for model_name in model_names:\n",
    "    with open(model_name + '_decoding_Js_stacked.pkl', 'rb') as f:\n",
    "        new_J = pickle.load(f)\n",
    "        J_dict.update(new_J)\n",
    "        print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecada48-bc8c-4d74-b8de-e8d89feb1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bures distances (takes a while)\n",
    "\n",
    "bures_dists_all_rbyn = jsutils.compute_Jacobian_Bures_distances(J_dict_rbyn, model_names)\n",
    "np.savez('bures_dists_penultimate_decoding_Jrbyn.npz', bures_dists = bures_dists_all_rbyn, model_names = model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4d5c6-d3f1-4cb6-9d73-2cffd10318bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bures distances (takes a while)\n",
    "# Because of the size of the flattened arrays, this one uses Procrustes distance for speed of computation\n",
    "\n",
    "bures_dists_all = jsutils.compute_Jacobian_Procrustes_distances(J_dict, model_names)\n",
    "np.savez('bures_dists_penultimate_decoding_Jstacked.npz', bures_dists = bures_dists_all, model_names = model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
