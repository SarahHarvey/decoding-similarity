{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12859f88-fdd1-4df7-9d03-74d64a0ce35e",
   "metadata": {},
   "source": [
    "### Compute and save Jacobians and Bures distances for analysis\n",
    "\n",
    "Example code extracting representations, computing Jacobians and Bures distances, and saving/loading all these things once computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699ef08b-aa14-4461-8952-b3173f9830d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import dsutils \n",
    "import metrics\n",
    "import jsutils\n",
    "import extract_internal_reps\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842b5cf2-34d5-429c-a452-d282de15a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'maxvit_t',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available models (from torch hub)\n",
    "\n",
    "avail_models = models.list_models(module=torchvision.models)\n",
    "avail_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3bdc7b-b8fe-41e7-b8c6-0816c11c0e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet101 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet152 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet34 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /mnt/home/sharvey/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n",
      "100%|██████████| 340M/340M [00:01<00:00, 182MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x8d done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_64x4d done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /mnt/home/sharvey/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n",
      "100%|██████████| 95.8M/95.8M [00:00<00:00, 190MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext50_32x4d done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufflenet_v2_x0_5 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufflenet_v2_x1_0 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufflenet_v2_x1_5 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufflenet_v2_x2_0 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_0 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_1 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_b done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_s done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_t done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_v2_b done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_v2_s done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_v2_t done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11_bn done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13_bn done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16_bn done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19_bn done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_b_16 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_b_32 done\n",
      "Using cpu for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Using cache found in /mnt/home/sharvey/.cache/torch/hub/pytorch_vision_main\n",
      "Downloading: \"https://download.pytorch.org/models/vit_h_14_swag-80465313.pth\" to /mnt/home/sharvey/.cache/torch/hub/checkpoints/vit_h_14_swag-80465313.pth\n",
      "100%|██████████| 2.36G/2.36G [00:30<00:00, 84.4MB/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Wrong image height! Expected 518 but got 224!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m avail_models[\u001b[38;5;241m45\u001b[39m:]: \u001b[38;5;66;03m#avail_models:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     repDict\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m---> 11\u001b[0m     x1, model_2nd \u001b[38;5;241m=\u001b[39m \u001b[43mextract_internal_reps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_rep_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     repDict[model] \u001b[38;5;241m=\u001b[39m [x1,model_2nd]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# model_2nds.append(model_2nd)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# internal_reps.append(x1)\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ceph/users/sharvey/decoding/decoding-similarity/extract_internal_reps.py:81\u001b[0m, in \u001b[0;36mextract_rep_gen\u001b[0;34m(model, data_dir, weights)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, _ \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[0;32m---> 81\u001b[0m         y1 \u001b[38;5;241m=\u001b[39m \u001b[43mtestmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y1, testmodel_2nd\n",
      "File \u001b[0;32m~/miniforge3/envs/da/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/da/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/da/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/da/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:271\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m n, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    270\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[0;32m--> 271\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrong image height! Expected \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m but got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mh\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(w \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image width! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m n_h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m p\n",
      "File \u001b[0;32m~/miniforge3/envs/da/lib/python3.12/site-packages/torch/__init__.py:2040\u001b[0m, in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhas_torch_function(\n\u001b[1;32m   2035\u001b[0m     (condition,)\n\u001b[1;32m   2036\u001b[0m ):\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(\n\u001b[1;32m   2038\u001b[0m         _assert, (condition,), condition, message\n\u001b[1;32m   2039\u001b[0m     )\n\u001b[0;32m-> 2040\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Wrong image height! Expected 518 but got 224!"
     ]
    }
   ],
   "source": [
    "# Extract representations resulting from probe inputs in data_dir\n",
    "\n",
    "data_dir = '../imagenet-sample-images'\n",
    "\n",
    "# internal_reps = []\n",
    "# model_2nds = []\n",
    "repDict = {}\n",
    "\n",
    "for model in avail_models[45:]: #avail_models:\n",
    "    repDict.clear()\n",
    "    x1, model_2nd = extract_internal_reps.extract_rep_gen(model, data_dir, weights=\"first\")\n",
    "    repDict[model] = [x1,model_2nd]\n",
    "    # model_2nds.append(model_2nd)\n",
    "    # internal_reps.append(x1)\n",
    "    with open(model + '_internal_rep_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(repDict, f)\n",
    "    print(model + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131f72b-b802-4e2f-8c0f-7b410d64a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract representations resulting from probe inputs in data_dir\n",
    "\n",
    "# OLD METHOD\n",
    "\n",
    "# data_dir = '../imagenet-sample-images'\n",
    "\n",
    "# internal_reps = []\n",
    "# model_2nds = []\n",
    "# repDict = {}\n",
    "\n",
    "# for model in model_names:\n",
    "#     x1, model_2nd = extract_internal_reps.extract_rep(model, data_dir)\n",
    "#     repDict[model] = [x1,model_2nd]\n",
    "#     model_2nds.append(model_2nd)\n",
    "#     internal_reps.append(x1)\n",
    "#     print(model + \" done\")\n",
    "\n",
    "# Save extracted representations\n",
    "\n",
    "# with open('internal_reps_with_model_2nd_half_full_classifier.pkl', 'wb') as f:\n",
    "#     pickle.dump(repDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a60eb3-e0b7-4024-82ef-9b5e53be914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet\n",
      "resnet18\n",
      "resnet34\n",
      "resnet50\n",
      "resnet101\n",
      "resnet152\n",
      "vgg16\n"
     ]
    }
   ],
   "source": [
    "# Load extracted representations\n",
    "\n",
    "# Load a specified set of internal reps in a dictionary \n",
    "\n",
    "repDict = {}\n",
    "\n",
    "# Models you want to load \n",
    "model_names = [\"alexnet\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\", \"vgg16\"]\n",
    "\n",
    "N_models = len(model_names)\n",
    "for model_name in model_names:\n",
    "    with open('reps/' + model_name + '_internal_rep_classifier.pkl', 'rb') as f:\n",
    "        new_reps = pickle.load(f)\n",
    "        repDict.update(new_reps)\n",
    "        print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d780bb-82f7-43c8-a108-15301945c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute decoding Jacobians and save\n",
    "\n",
    "# Takes a while\n",
    "\n",
    "import pickle\n",
    "J_dict_rbyn = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    J_dict_rbyn.clear()\n",
    "    Js = jsutils.decoding_jacobian(repDict[model_name][0], repDict[model_name][1])\n",
    "    J_dict_rbyn[model_name] = Js\n",
    "    with open(model_name + '_decoding_Js_rbyn.pkl', 'wb') as f:\n",
    "        pickle.dump(J_dict_rbyn, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d40dcd-55db-48fd-9e67-3bad746889a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Jacobian lists from a list of M, r by N Jacobians to a list of r, M by N Jacobians (if desired)\n",
    "\n",
    "J_dict_mbyn = {}\n",
    "for model_name in model_names:\n",
    "    J_dict_mbyn.clear()\n",
    "    Js_mbyn = jsutils.convert_Jacobian(J_dict_rbyn, model_name)\n",
    "    J_dict_mbyn[model_name] = Js_mbyn\n",
    "    with open(model_name + '_decoding_Js_mbyn.pkl', 'wb') as f:\n",
    "        pickle.dump(J_dict_mbyn, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6a9dd-0a66-45bb-ab5a-a737737bd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Jacobians\n",
    "\n",
    "J_dict = jsutils.flatten_Jacobian(J_dict_rbyn)\n",
    "\n",
    "for model_name in model_names:\n",
    "    Js = {model_name: J_dict[model_name]}\n",
    "    with open(model_name + '_decoding_Js_stacked.pkl', 'wb') as f:\n",
    "        pickle.dump(Js, f)\n",
    "    print(model_name + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4ce74-8632-4a60-823d-351a2225b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jacobians\n",
    "# loads a subset of models' Jacobians\n",
    "\n",
    "J_dict = {}\n",
    "\n",
    "model_names = [\"alexnet\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\",\"vgg16\"]\n",
    "\n",
    "N_models = len(model_names)\n",
    "for model_name in model_names:\n",
    "    with open(model_name + '_decoding_Js_stacked.pkl', 'rb') as f:\n",
    "        new_J = pickle.load(f)\n",
    "        J_dict.update(new_J)\n",
    "        print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecada48-bc8c-4d74-b8de-e8d89feb1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bures distances (takes a while)\n",
    "\n",
    "bures_dists_all_rbyn = jsutils.compute_Jacobian_Bures_distances(J_dict_rbyn, model_names)\n",
    "np.savez('bures_dists_penultimate_decoding_Jrbyn.npz', bures_dists = bures_dists_all_rbyn, model_names = model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4d5c6-d3f1-4cb6-9d73-2cffd10318bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bures distances (takes a while)\n",
    "# Because of the size of the flattened arrays, this one uses Procrustes distance for speed of computation\n",
    "\n",
    "bures_dists_all = jsutils.compute_Jacobian_Procrustes_distances(J_dict, model_names)\n",
    "np.savez('bures_dists_penultimate_decoding_Jstacked.npz', bures_dists = bures_dists_all, model_names = model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
